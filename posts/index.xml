<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Rizwan Khanüë®üèª‚Äçüíª</title>
        <link>https://rizwan-kh.github.io/posts/</link>
        <description>Recent content in Posts on Rizwan Khanüë®üèª‚Äçüíª</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
        <lastBuildDate>Mon, 21 Jun 2021 11:16:23 +0400</lastBuildDate>
        <atom:link href="https://rizwan-kh.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>Azure DevOps - Send Json Request(Parameters)</title>
            <link>https://rizwan-kh.github.io/posts/2021/06/azure-devops-send-json-requestparameters/</link>
            <pubDate>Mon, 21 Jun 2021 11:16:23 +0400</pubDate>
            
            <guid>https://rizwan-kh.github.io/posts/2021/06/azure-devops-send-json-requestparameters/</guid>
            <description>Introduction If you&amp;rsquo;ve been using Azure DevOps, you would know that a pipeline can be trigger with runtime parameters in the format key: value pair and this is great for doing almost all of the tasks.
For our use-case, we had been looking at option to send a JSON based parameter dictionary and I couldn&amp;rsquo;t find any way at the time of writing this article. We came up with a hack to achieve this and I would want to write it up in this blog post.</description>
            <content type="html"><![CDATA[<h3 id="introduction">Introduction</h3>
<p>If you&rsquo;ve been using Azure DevOps, you would know that a pipeline can be trigger with runtime parameters in the format <code>key: value</code> pair and this is great for doing almost all of the tasks.</p>
<p>For our use-case, we had been looking at option to send a JSON based parameter dictionary and I couldn&rsquo;t find any way at the time of writing this article. We came up with a hack to achieve this and I would want to write it up in this blog post.</p>
<h3 id="flatten-json--operation">Flatten JSON &amp; operation</h3>
<p>Wee look at the option to use the Flatten JSON Objects extension to convert a nested data layer object into a new object with only one layer of key/value pairs. For this we used the <strong>flatten_json</strong> library</p>
<p><code>pip install flatten_json</code></p>
<pre><code>'''
flatten the json data with a '_' separator; you can use different separator as well
'''
# flatten.py
import flatten_json

data = {
    &quot;a&quot;: 1,
    &quot;b&quot;: 2,
    &quot;c&quot;: [{&quot;d&quot;: [2, 3, 4], &quot;e&quot;: [{&quot;f&quot;: 1, &quot;g&quot;: 2}]}]
}
flat_json = flatten_json.flatten(data,'_')
print(flat_json)
'''
the above command gives us below output, which is single layer JSON
{
 'a': 1,
 'b': 2,
 'c_0_d_0': 2,
 'c_0_d_1': 3,
 'c_0_d_2': 4,
 'c_0_e_0_f': 1,
 'c_0_e_0_g': 2
 }
'''
</code></pre><p>Now that we had single layer <code>key: value</code> pair, we added another hack to be able to read these variables properly in Azure DevOps pipeline. We added a prefix (any prefix that&rsquo;s not part of your JSON) <strong>RizwanGotNoChill-</strong></p>
<pre><code>prefixed_flat_json = {f&quot;RizwanGotNoChill-{key}&quot;: val for key, val in flat_json.items()}
print(prefixed_flat_json)
'''
the above command gives us below output, which is single layer prefixed JSON
{
 'RizwanGotNoChill-a': 1,
 'RizwanGotNoChill-b': 2,
 'RizwanGotNoChill-c_0_d_0': 2,
 'RizwanGotNoChill-c_0_d_1': 3,
 'RizwanGotNoChill-c_0_d_2': 4,
 'RizwanGotNoChill-c_0_e_0_f': 1,
 'RizwanGotNoChill-c_0_e_0_g': 2
 }
'''
</code></pre><p>This part if all we needed, now you could use the Azure DevOps Rest API with above <code>key: value</code> pair to trigger any pipeline and I will show, how we intepreted these at the pipeline and crafted a JSON out.</p>
<h3 id="trigger-azure-devops-pipeline">Trigger Azure DevOps Pipeline</h3>
<p>I found the below two ways to trigger a pipeline, you may want to see which one fits your case -</p>
<ul>
<li>Using REST API based curl/http command calling the <strong>build API</strong> - <a href="https://dev.azure.com/YOURORG/YOURPROJECT/_apis/build/builds?api-version=6.1-preview.6">https://dev.azure.com/YOURORG/YOURPROJECT/_apis/build/builds?api-version=6.1-preview.6</a>)</li>
</ul>
<ol>
<li>Convert you JSON to an escaped one using this <a href="https://jsonformatter.org/json-escape">link</a></li>
<li>Create the request param as below and send</li>
</ol>
<pre><code># Replace the values for YOURORG, YOURPROJECT, PATTOKEN and the value for id(pipeline ID)
curl --request POST \
  --url 'https://dev.azure.com/YOURORG/YOURPROJECT/_apis/build/builds?api-version=6.1-preview.6' \
  --header 'Authorization: Basic PATTOKEN' \
  --header 'Content-Type: application/json' \

  --data '{
    &quot;parameters&quot;: &quot;{\&quot;RizwanGotNoChill-a\&quot;:1,\&quot;RizwanGotNoChill-b\&quot;:2,\&quot;RizwanGotNoChill-c_0_d_0\&quot;:2,\&quot;RizwanGotNoChill-c_0_d_1\&quot;:3,\&quot;RizwanGotNoChill-c_0_d_2\&quot;:4,\&quot;RizwanGotNoChill-c_0_e_0_f\&quot;:1,\&quot;RizwanGotNoChill-c_0_e_0_g\&quot;:2}&quot;,
    &quot;definition&quot;:  { &quot;id&quot;:  27 }
}'
</code></pre><ul>
<li>The other way to trigger a pipeline is calling the <strong>RunPipeline API</strong>, I wrote a small program</li>
</ul>
<script type="application/javascript" src="https://gist.github.com/rizwan-kh/c08955a24bfc1eb3eaa48248acd012e0.js"></script>

<h3 id="unflatten-json--operation">Unflatten JSON &amp; operation</h3>
<p>Now the baton is at the Azure DevOps end to decode and re-configure this as a JSON, I used a simple job and Python script to achieve this</p>
<pre><code># azure-pipeline.yml
- job: install_library
  steps:
  - checkout: none
  - script: |
      pip3 install flatten_json
      pip3 freeze
      displayName: Install python library

- job: generate_files
  steps:
  - script: |
      echo &quot;Here, we will grep the content based on the prefix and store in a file&quot;
      env | grep RizwanGotNoChill &gt; request.txt
      sed -i 's/RizwanGotNoChill-//' request.txt
      echo &quot;utils.py first creates a dict based on request.txt and then unflattens the files and write to request.json&quot;
      python3 utils.py
      cat request.json | jq .
</code></pre><pre><code># utils.py
import os, sys
import json
import flatten_json

dict_from_file = {}
with open(&quot;request.txt&quot;) as fp:
    for line in fp:
        (key, val) = line.split(&quot;=&quot;)
        dict_from_file[key.lower()] = val.rstrip(&quot;\n&quot;)
print(dict_from_file)

request_json = flatten_json.unflatten(dict_from_file, '-')
print(request_json)

with open('request.json', 'w') as fp:
     fp.write(json.dumps(request_json))

</code></pre><p>Here our <code>request.json</code> is a proper JSON file ready to be used by any application/program in our Azure Pipeline;
We noticed one issue though, the conversion process, converts all other data types to string data-type, so might be you would need to change that or add some logic to create json/dict with type safe.</p>
]]></content>
        </item>
        
        <item>
            <title>Hugo &amp; GitHub - Setup Static Website on GitHub</title>
            <link>https://rizwan-kh.github.io/posts/2020/06/hugo-github-setup-static-website-on-github/</link>
            <pubDate>Fri, 12 Jun 2020 22:32:01 +0400</pubDate>
            
            <guid>https://rizwan-kh.github.io/posts/2020/06/hugo-github-setup-static-website-on-github/</guid>
            <description>Hugo and Github Account A small write-up on how this site was setup. There are plenty of materials available all over the internet, but this is more of a self-help document for myself to refer back in future to understand how this was all setup.
 Hugo can be downloaded from their official release page A GitHub account needs to be created from this link and a public repo is required to be setup here  After installing Hugo, to generate a new site, run the below command:</description>
            <content type="html"><![CDATA[<p><img src="/hugo-logo-wide.svg" alt="Hub"></p>
<h2 id="hugo-and-github-account">Hugo and Github Account</h2>
<p>A small write-up on how <a href="https://rizwan-kh.github.io">this site</a> was setup. There are plenty of materials available all over the internet, but this is more of a self-help document for myself to refer back in future to understand how this was all setup.</p>
<ul>
<li>Hugo can be downloaded from their official <a href="https://github.com/gohugoio/hugo/releases">release page</a></li>
<li>A GitHub account needs to be created from <a href="https://github.com/join">this link</a> and a public repo is required to be setup <a href="https://github.com/new">here</a></li>
</ul>
<p>After installing <strong>Hugo</strong>, to generate a new site, run the below command:</p>
<pre><code>hugo new site rizwan-blogs
</code></pre><p>This will automatically create a directory named <em>rizwan-blogs</em> which will contain the necessary sub-directories and files required for our new hugo-based static website.</p>
<p>The <code>config.toml</code> file is the main configuration file where we can add/change the theme or add additional settings like title, author, etc. Sample <strong>config.toml</strong> looks like below</p>
<pre><code>baseURL = &quot;https://rizwan-kh.github.io&quot;
title = &quot;Rizwan Khanüë®üèª‚Äçüíª&quot;
languageCode = &quot;en-us&quot;
theme = &quot;hello-friend-ng&quot;

</code></pre><p>Replace the above 4 values as you want to in the config.toml and you are good to go.</p>
<p>To add content/pages, we run the below command, this will create a markdown page with the post marked as <code>draft: true</code> and we can keep it as true until we want to publish the post.</p>
<pre><code>huge new posts/my-post.md
</code></pre><p>Fire up your favorite editor and it&rsquo;s all <a href="https://www.markdownguide.org/cheat-sheet/">markdown</a> from there.
Then we can start the hugo server in build drafts enabled mode (or as I think of it as development mode) with the below command and it will let you browse the site on address <a href="http://localhost:1313/">localhost:1313</a> with auto-refresh mode on.</p>
<pre><code>hugo server -D
</code></pre><p>When the pages/posts are ready to be published, simply run the server in publish mode and hugo will take care of generating the required files in <code>./public</code> directory,
<em>Note: Make sure to clean up the public directory, as the directory will contain drafts pages as well from the previous run</em></p>
<pre><code>hugo
</code></pre><h4 id="deploy-your-website">Deploy your website</h4>
<p>The final production content in stored in the public directory and we just need to copy the directory in the production server either on <strong>AWS S3</strong>, or on <strong>GitHub Pages</strong></p>
<hr>
<p>Now for the publishing the website, Go to <a href="https://github.com">GitHub</a> and create a <a href="https://github.com/new">new public repository</a> named <em><strong>username.github.io</strong></em>, where <em><strong>username</strong></em> is your username (or organization name) on GitHub.</p>
<p>Use any <strong>git</strong> client to clone the repo, copy over the entire <em>public</em> directory</p>
<pre><code>git clone https://github.com/username/username.github.io
cd username.github.io
</code></pre><p>copy over the entire content of the <code>public</code> directory <code>username.github.io</code> and use git to commit and push the content over to <em>GitHub</em></p>
<pre><code>git add --all
git commit -m &quot;initial commit&quot;
git push origin main
</code></pre><p>open your browser and type up the URL <a href="https://username.github.io">username.github.io</a> and voila your static website content is up and ready for free.</p>
]]></content>
        </item>
        
        <item>
            <title>Klar</title>
            <link>https://rizwan-kh.github.io/posts/2020/03/klar/</link>
            <pubDate>Sat, 14 Mar 2020 17:20:26 +0400</pubDate>
            
            <guid>https://rizwan-kh.github.io/posts/2020/03/klar/</guid>
            <description>Introduction Klar is a static binary tool to analyze images stored in a private or public Docker registry for security vulnerabilities using Clair. Klar is designed to be used as an integration tool so it relies on environment variables. It&amp;rsquo;s a single binary which requires no dependencies and can be plugged and/or integrated into our CI CD pipelines.
Klar serves as a client which coordinates the image checks between the Docker registry and Clair.</description>
            <content type="html"><![CDATA[<h3 id="introduction">Introduction</h3>
<p><a href="https://github.com/optiopay/klar">Klar</a> is a static binary tool to analyze images stored in a private or public Docker registry for security vulnerabilities using <a href="https://github.com/coreos/clair">Clair</a>. Klar is designed to be used as an integration tool so it relies on environment variables. It&rsquo;s a single binary which requires no dependencies and can be plugged and/or integrated into our CI CD pipelines.</p>
<p>Klar serves as a client which coordinates the image checks between the Docker registry and Clair. We heavily use klar along with Clair in our internal CI CD pipeline to scan the newly built Docker images.</p>
<hr>
<h4 id="installation">Installation</h4>
<p>Download the latest release (for OSX and Linux) from <a href="https://github.com/optiopay/klar/releases/">https://github.com/optiopay/klar/releases/</a> and put the binary in a directory which is present in your PATH variable (make sure it has execute permission set).</p>
<hr>
<h4 id="usage">Usage</h4>
<p>Klar process returns if 0 if the number of detected high severity vulnerabilities in an image is less than or equal to a threshold (see below) and 1 if there were more. It will return 2 if an error has prevented the image from being analyzed.</p>
<p>Klar can be configured via the following environment variables:</p>
<table>
<thead>
<tr>
<th>Variable</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>CLAIR_ADDR</strong></td>
<td>address of Clair server. It has a form of protocol://host:port - protocol and port default to http and 6060 respectively and may be omitted. You can also specify basic authentication in the URL: protocol://login:password@host:port</td>
</tr>
<tr>
<td><strong>CLAIR_OUTPUT</strong></td>
<td>severity level threshold, vulnerabilities with severity level higher than or equal to this threshold will be outputted. Supported levels are Unknown, Negligible, Low, Medium, High, Critical, Defcon1. Default is Unknown</td>
</tr>
<tr>
<td><strong>CLAIR_THRESHOLD</strong></td>
<td>how many outputted vulnerabilities Klar can tolerate before returning 1. Default is 0</td>
</tr>
<tr>
<td><strong>CLAIR_TIMEOUT</strong></td>
<td>timeout in minutes before Klar cancels the image scanning. Default is 1</td>
</tr>
<tr>
<td><strong>DOCKER_USER</strong></td>
<td>Docker registry account name</td>
</tr>
<tr>
<td><strong>DOCKER_PASSWORD</strong></td>
<td>Docker registry account password</td>
</tr>
<tr>
<td><strong>DOCKER_TOKEN</strong></td>
<td>Docker registry account token. (Can be used in place of DOCKER_USER and DOCKER_PASSWORD)</td>
</tr>
<tr>
<td><strong>DOCKER_INSECURE</strong></td>
<td>Allow Klar to access registries with bad SSL certificates. Default is false. Clair will need to be booted with -insecure-tls for this to work</td>
</tr>
<tr>
<td><strong>DOCKER_TIMEOUT</strong></td>
<td>timeout in minutes when trying to fetch layers from a docker registry</td>
</tr>
<tr>
<td><strong>DOCKER_PLATFORM_OS</strong></td>
<td>The operating system of the Docker image. Default is linux. This only needs to be set if the image specified references a Docker ManifestList instead of a usual manifest</td>
</tr>
<tr>
<td><strong>DOCKER_PLATFORM_ARCH</strong></td>
<td>The architecture the Docker image is optimized for. Default is amd64. This only needs to be set if the image specified references a Docker ManifestList instead of a usual manifest</td>
</tr>
<tr>
<td><strong>REGISTRY_INSECURE</strong></td>
<td>Allow Klar to access insecure registries (HTTP only). Default is false</td>
</tr>
<tr>
<td><strong>JSON_OUTPUT</strong></td>
<td>Output JSON, not plain text. Default is false</td>
</tr>
<tr>
<td><strong>FORMAT_OUTPUT</strong></td>
<td>Output format of the vulnerabilities. Supported formats are standard, json, table. Default is standard. If JSON_OUTPUT is set to true, this option is ignored</td>
</tr>
<tr>
<td><strong>WHITELIST_FILE</strong></td>
<td>Path to the YAML file with the CVE whitelist. Look at whitelist-example.yaml for the file format</td>
</tr>
<tr>
<td><strong>IGNORE_UNFIXED</strong></td>
<td>Do not count vulnerabilities without a fix towards the threshold</td>
</tr>
</tbody>
</table>
<h4 id="usage-1">Usage:</h4>
<pre><code>CLAIR_ADDR=localhost;CLAIR_OUTPUT=High;CLAIR_THRESHOLD=10;DOCKER_USER=docker;DOCKER_PASSWORD=secret;
klar mysql:latest
</code></pre><h5 id="debug-output">Debug Output</h5>
<p>You can enable more verbose output but setting KLAR_TRACE to true.</p>
<h2 id="run-export-klar_tracetrue-to-persist-between-runs">run <code>export KLAR_TRACE=true</code> to persist between runs.</h2>
<h4 id="gitlab-ci-usage">GitLab CI Usage</h4>
<p>We have the below job defined in <code>.gitlab-ci.yml</code> post Dockerbuild stage</p>
<pre><code>image_analysis:
  stage: analyse
  image: registry.mycompany.com/ci/kubernetes-deploy:klar
  script:
    - export PATH=$PATH:$CI_PROJECT_DIR
    - export TAG=&quot;$CI_BUILD_REF_NAME&quot;
    - CLAIR_THRESHOLD=1000 DOCKER_TIMEOUT=5 CLAIR_TIMEOUT=5 CLAIR_ADDR=https://ngclair.mycompany.com:443 DOCKER_USER=gitlab-ci-token DOCKER_PASSWORD=$CI_BUILD_TOKEN klar $CI_REGISTRY_IMAGE:$TAG | tee scan.txt
  artifacts:
    paths:
      - $CI_PROJECT_DIR/scan.txt
    expire_in: 1 hour
  tags:
    - my_runner

</code></pre><p>This image <code>registry.mycompany.com/ci/kubernetes-deploy:klar</code> contains the klar binary and the clair server is running on <a href="https://ngclair.mycompany.com">https://ngclair.mycompany.com</a>:443</p>
]]></content>
        </item>
        
        <item>
            <title>Vagrant</title>
            <link>https://rizwan-kh.github.io/posts/2020/03/vagrant/</link>
            <pubDate>Sat, 14 Mar 2020 17:20:26 +0400</pubDate>
            
            <guid>https://rizwan-kh.github.io/posts/2020/03/vagrant/</guid>
            <description>Introduction  Getting started with Vagrant Download the install the Vagrant from the Download section
vagrant version Installed Version: 2.2.10 Latest Version: 2.2.10 You&#39;re running an up-to-date version of Vagrant! Download and install VirtualBox
Now if both Vagrant and VirtualBox are up and running, all we need to do is run the below 3 commands to have a Ubuntu VM up and available for our use in no time.
vagrant init hashicorp/bionic64 vagrant up vagrant ssh This is a pretty simple way to spin up a new Ubuntu VM, we can do a lot more which I will try to write up in later posts.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<hr>
<h2 id="getting-started-with-vagrant">Getting started with Vagrant</h2>
<p>Download the install the <a href="https://www.vagrantup.com/downloads">Vagrant</a> from the Download section</p>
<pre><code>vagrant version
Installed Version: 2.2.10
Latest Version: 2.2.10

You're running an up-to-date version of Vagrant!
</code></pre><p>Download and install <a href="https://www.virtualbox.org/wiki/Downloads">VirtualBox</a></p>
<p>Now if both <strong>Vagrant</strong> and <strong>VirtualBox</strong> are up and running, all we need to do is run the below 3 commands to have a Ubuntu VM up and available for our use in no time.</p>
<pre><code>vagrant init hashicorp/bionic64
vagrant up
vagrant ssh
</code></pre><p>This is a pretty simple way to spin up a new Ubuntu VM, we can do a lot more which I will try to write up in later posts.</p>
]]></content>
        </item>
        
        <item>
            <title>Gitlab CI &amp; Kaniko to build Docker Images</title>
            <link>https://rizwan-kh.github.io/posts/2020/02/gitlab-ci-kaniko-to-build-docker-images/</link>
            <pubDate>Wed, 12 Feb 2020 12:11:00 +0400</pubDate>
            
            <guid>https://rizwan-kh.github.io/posts/2020/02/gitlab-ci-kaniko-to-build-docker-images/</guid>
            <description>Introduction You can build container images from a Dockerfile inside a container or a Kubernetes cluster, though J√©r√¥me Petazzoni strongly discourages from doing so. He wrote a detailed blog that can be read here on why not to build container images using Dockerfile inside a container or a Kubernetes cluster.
 Context You will get N number of blogs on how to use the CI/CD of GitLab; here we will see an easy reference point to extend a file and create CI/CD for Docker Image to be built and stored in the same GitLab registry using kaniko.</description>
            <content type="html"><![CDATA[<p><img src="/gitlab.jpeg" alt="GitLab"></p>
<h3 id="introduction">Introduction</h3>
<p>You can build container images from a Dockerfile inside a container or a Kubernetes cluster, though <em>J√©r√¥me Petazzoni</em> strongly discourages from doing so. He wrote a detailed blog that can be read <a href="http://jpetazzo.github.io/2015/09/03/do-not-use-docker-in-docker-for-ci/">here</a> on why not to build container images using Dockerfile inside a container or a Kubernetes cluster.</p>
<hr>
<h4 id="context">Context</h4>
<p>You will get <code>N</code> number of blogs on how to use the CI/CD of GitLab; here we will see an easy reference point to extend a file and create CI/CD for Docker Image to be built and stored in the same GitLab registry using <a href="https://cloud.google.com/blog/products/gcp/introducing-kaniko-build-container-images-in-kubernetes-and-google-container-builder-even-without-root-access">kaniko</a>. This file needs to be created in the individual project in the GitLab using the template available with the name .gitlab-ci.yml.</p>
<hr>
<h4 id="what-is-kaniko">What is Kaniko?</h4>
<p><code>Note: Kaniko is not an officially supported Google product</code>
It is a tool to build container images from a Dockerfile inside a container or a Kubernetes cluster. It doesn&rsquo;t depend on the Docker daemon to run each Dockerfile command.</p>
<p>It comes with it&rsquo;s own limitations, but we don&rsquo;t run the risk of using Docker-in-Docker</p>
<hr>
<h4 id="prerequisites">Prerequisites</h4>
<ul>
<li>Access to GitLab (either private self hosted or managed)</li>
<li>GitLab project with a Dockerfile</li>
</ul>
<hr>
<h4 id="ci-yaml-for-auto-devops">CI YAML for auto-devops</h4>
<pre><code># .gitlab-ci.yml
variables:
    GIT_SSL_NO_VERIFY: &quot;true&quot;

before_script:
  - echo &quot;Random image creation, user = $GITLABUSER&quot;

stages:
  - build

build_image:
  image:
    name: gcr.io/kaniko-project/executor:debug
    entrypoint: [&quot;&quot;]
  stage: build
  script:
    - ls
    - pwd
    - export CI_REGISTRY_IMAGE=mygitlab.com/base-project/subproject/project
    - echo &quot;{\&quot;auths\&quot;:{\&quot;mygitlab.com\&quot;:{\&quot;username\&quot;:\&quot;gitlab-ci-token\&quot;,\&quot;password\&quot;:\&quot;$CI_BUILD_TOKEN\&quot;},\&quot;repository.xyz-company.io\&quot;:{\&quot;username\&quot;:\&quot;user\&quot;,\&quot;password\&quot;:\&quot;123random\&quot;}}}&quot; &gt; /kaniko/.docker/config.json
    - wget https://letsencrypt.org/certs/lets-encrypt-x3-cross-signed.pem | xargs cat lets-encrypt-x3-cross-signed.pem &gt;&gt; /kaniko/ssl/certs/ca-certificates.crt
    - /kaniko/executor --skip-tls-verify --context $CI_PROJECT_DIR --dockerfile $CI_PROJECT_DIR/Dockerfile --destination $CI_REGISTRY_IMAGE:$CI_BUILD_REF_NAME

</code></pre><hr>
<p><strong>variables</strong>: These are static values which aren&rsquo;t going to change and is used at multiple location in the gitlab-ci.yml file</p>
<p><strong>before_script</strong>: Set(s) of commands or echo statement we want to print</p>
<p><strong>stages</strong>: Stages are block of code for an identical job or set of jobs viz. build, test, clean-up, delete, deploy, etc. This executes in the order it&rsquo;s defined in the YAML. A dot(.) in front of any job(block of code) disables it and it won&rsquo;t be executed or available neither as an automatic or manual job.</p>
<p><strong>Jobs (Each block of code)</strong>: Each block of individual stage contains key-value pair or set of commands to it. We can define each block of code to point to a particular stage and all the set of commands it requires to perform that function in the script block. It can be made to run automatically and also manual (start the job manually by clicking a button). The variables like password, access/secret key can be defined in the CI/CD settings under secret variables section so it&rsquo;s not available in plain text format.</p>
<hr>
<p><strong>Note</strong>: If you want to use the GitLab docker registry and store docker images in the GitLab project; this by default is disabled and needs to be enabled in the General setting section.</p>
]]></content>
        </item>
        
        <item>
            <title>How to use service accounts for Kubernetes imagePullSecrets</title>
            <link>https://rizwan-kh.github.io/posts/2020/01/how-to-use-service-accounts-for-kubernetes-imagepullsecrets/</link>
            <pubDate>Thu, 02 Jan 2020 17:40:27 +0400</pubDate>
            
            <guid>https://rizwan-kh.github.io/posts/2020/01/how-to-use-service-accounts-for-kubernetes-imagepullsecrets/</guid>
            <description>What are Service Accounts in Kubernetes? As per Kubernetes.io - A service account provides an identity for processes that run in a Pod.
One can think of service accounts as service users for pods. They help pods authenticate with the api-server and interact with it.
 Many times, we come across a situation where our organization uses a private Docker registry to store the Docker images and to make this available we need to create a docker-registry kubernetes secret and pass as imagePullSecrets in the deployment manifest.</description>
            <content type="html"><![CDATA[<p><img src="/kubernetes.jpg" alt="Kubernetes"></p>
<h2 id="what-are-service-accounts-in-kubernetes">What are Service Accounts in Kubernetes?</h2>
<p>As per <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/">Kubernetes.io</a> - A service account provides an identity for processes that run in a Pod.</p>
<p>One can think of service accounts as service users for pods. They help pods authenticate with the api-server and interact with it.</p>
<h2 id="heading"></h2>
<p>Many times, we come across a situation where our organization uses a private Docker registry to store the Docker images and to make this available we need to create a <code>docker-registry</code> kubernetes secret and pass as <code>imagePullSecrets</code> in the deployment manifest.</p>
<pre><code>kubectl create secret docker-registry registry-cred \
 --docker-server=my.private-registry.com \
 --docker-username=my_username \
 --docker-password=&quot;my_superr_strong_password&quot; \
 --docker-email=my.email@mycompany.com -n my-namespace
</code></pre><p>Then, we pass this secret in the deployment manifest as below.</p>
<pre><code>...
      imagePullSecrets:
      - name: registry-cred
...

</code></pre><h2 id="the-problem-with-this-approach">The problem with this approach?</h2>
<p>Not many that I can think of, except below ones:</p>
<ul>
<li>The deployment yaml are generally developed by Developers who doesn&rsquo;t need to know about this credentials</li>
<li>If there are a large number of pods in the namespace, then each manifest needs to be updated, whenever the password is rotated</li>
</ul>
<h2 id="the-solution">The solution</h2>
<p><code>serviceAccounts</code> - your Kubernetes administrator can just patch serviceAccounts with the registry credential secret and you don&rsquo;t need to worry about replacing or adding it in your manifest yaml each time.</p>
<pre><code>kubectl patch serviceaccount default \
-p '{&quot;imagePullSecrets&quot;: [{&quot;name&quot;: &quot;registry-cred&quot;}]}' -n my-namespace
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Docker Cheat Sheet</title>
            <link>https://rizwan-kh.github.io/posts/2019/10/docker-cheat-sheet/</link>
            <pubDate>Fri, 11 Oct 2019 05:11:13 +0400</pubDate>
            
            <guid>https://rizwan-kh.github.io/posts/2019/10/docker-cheat-sheet/</guid>
            <description>Below are few of the main and basic commands used in Docker, an easy pick-up and good-to-go command page for docker troubleshooting.
Alias  If you are a lazy developer/sysadmin like me, the first thing you should do on your system is to make easy alias of all the long commands, below are the ones I often use on any system I use on a daily basis:
These can be imported on ~/.</description>
            <content type="html"><![CDATA[<p><img src="/docker.png" alt="docker">
Below are few of the main and basic commands used in Docker, an easy pick-up and good-to-go command page for docker troubleshooting.</p>
<h2 id="alias">Alias</h2>
<hr>
<p>If you are a lazy developer/sysadmin like me, the first thing you should do on your system is to make easy alias of all the long commands, below are the ones I often use on any system I use on a  daily basis:</p>
<p>These can be imported on ~/.bashrc (if you use bash) or ~/.zshrc (if you are a MAC user and use ZSH)</p>
<pre><code>alias docker='sudo docker'
alias dock='sudo docker'
alias di='sudo docker images'
alias drun='sudo docker run -ti'
alias dbuild='sudo docker build'
alias dexec='sudo docker exec -ti'
alias dps='sudo docker ps -a'
alias dpsq='sudo docker ps -a -q'
alias drm='sudo docker rm'
alias drmi='sudo docker rmi'
alias dstop='sudo docker stop'

</code></pre><h3 id="commands-and-their-usage">Commands and their usage</h3>
<p>Mostly used commands are aliased above, but to explain what each does, please read on</p>
<pre><code># to build a docker image with a certain name and certain tag, use the below Docker build comamnd
docker build --tag imagename:tagname --file /path/to/Dockerfile


# to check the docker images
docker images


# to run a docker container in detach mode publishing hostport:containerport and mounting a host vol to container vol, giving a name to the runnging container and the hostname to container
docker run --tty --interactive --publish 2222:22 --hostname my-x-host --volume /hostvolume:/containervol --name name-of-running-container --detach imagename:tagname
# docker run -ti -p 2222:22 -h my-x-host -v /hostvolume:/containervol -n name-of-running-container -d imagename:tagname (this is shorter version of the above command)


# to see all running containers
docker ps


# to see all containers (running, stopped, exited, etc.)
docker ps -a


# to get inside a running container
docker exec -ti CONTAINERNAME/CONTAINERID bash


# to stop a running container
docker stop CONTAINERNAME/CONTAINERID


# to remove a stopped container
docker rm CONTAINERNAME/CONTAINERID

# to see logs from containers
docker logs CONTAINERNAME/CONTAINERID
</code></pre>]]></content>
        </item>
        
        <item>
            <title>tmux</title>
            <link>https://rizwan-kh.github.io/posts/2019/06/tmux/</link>
            <pubDate>Thu, 13 Jun 2019 21:53:35 +0400</pubDate>
            
            <guid>https://rizwan-kh.github.io/posts/2019/06/tmux/</guid>
            <description>tmux - Terminal Multiplexer tmux is a terminal multiplexer. It helps switch between multiple programs in one terminal, detach them(they keep running in background) and reattach when needed. I started using tmux as someone recommended me to start using it as it helps with CKA &amp;amp; CKAD (which I have still not attempted) and then later on I was heavily using it for my website(with Hugo). I had previously used mPutty, but mPutty uses mutliple logged in sessions to display on screen, whereas tmux simply multiply the existing sessions on screen.</description>
            <content type="html"><![CDATA[<p><img src="/tmux-logo.png" alt="tmux"></p>
<h1 id="tmux---terminal-multiplexer">tmux - Terminal Multiplexer</h1>
<p>tmux is a terminal multiplexer. It helps switch between multiple programs in one terminal, detach them(they keep running in background) and reattach when needed. I started using tmux as someone recommended me to start using it as it helps with CKA &amp; CKAD (which I  have still not attempted) and then later on I was heavily using it for my website(with Hugo). I had previously used mPutty, but mPutty uses mutliple logged in sessions to display on screen, whereas tmux simply multiply the existing sessions on screen.</p>
<h3 id="installation">Installation</h3>
<p>Major distribution of linux provides tmux packages via standard pre-built packages of tmux.</p>
<table>
<thead>
<tr>
<th>Platform</th>
<th>Install Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>Debian or Ubuntu</td>
<td><code>apt install tmux</code></td>
</tr>
<tr>
<td>RHEL or CentOS</td>
<td><code>yum install tmux</code></td>
</tr>
<tr>
<td>macOS (using Homebrew)</td>
<td><code>brew install tmux</code></td>
</tr>
</tbody>
</table>
<h3 id="basic-commands-and-usage">Basic commands and usage</h3>
<table>
<thead>
<tr>
<th align="left">Command</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">tmux</td>
<td align="left">start a new session</td>
</tr>
<tr>
<td align="left">tmux new -s my-kube-session</td>
<td align="left">start a new session with name</td>
</tr>
<tr>
<td align="left">tmux a</td>
<td align="left">attach</td>
</tr>
<tr>
<td align="left">tmux a  -t my-kube-session</td>
<td align="left">attach to a named session</td>
</tr>
<tr>
<td align="left">tmux ls</td>
<td align="left">list all tmux sessions</td>
</tr>
<tr>
<td align="left">tmux kill-session -t my-kube-session</td>
<td align="left">kill the session named my-kube-session</td>
</tr>
</tbody>
</table>
<p>After a session is created, inside to perform any action, we need to hit <code>ctrl+b</code> followed by any below command/keystroke</p>
<table>
<thead>
<tr>
<th align="left">Keystroke</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">ctrl+b -&gt; c</td>
<td align="left">create new shell</td>
</tr>
<tr>
<td align="left">ctrl+b -&gt; n</td>
<td align="left">next shell</td>
</tr>
<tr>
<td align="left">ctrl+b -&gt; p</td>
<td align="left">previous shell</td>
</tr>
<tr>
<td align="left">ctrl+b -&gt; d</td>
<td align="left">detach session</td>
</tr>
<tr>
<td align="left">ctrl+b -&gt; %</td>
<td align="left">vertical split</td>
</tr>
<tr>
<td align="left">ctrl+b -&gt; &quot;</td>
<td align="left">horizontal split</td>
</tr>
<tr>
<td align="left">ctrl+b -&gt; [arrow keys]</td>
<td align="left">to switch between the vertical/horizontal panes</td>
</tr>
<tr>
<td align="left">ctrl+b -&gt; z</td>
<td align="left">zoom in and zoom out between split panes</td>
</tr>
</tbody>
</table>
<p>That&rsquo;s all more or less the keystroke you need to know; It comes of naturally when you start using it after a few days but until then - you can refer these as needed.</p>
]]></content>
        </item>
        
    </channel>
</rss>
