<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>pipelines on Rizwan Khanüë®üèª‚Äçüíª</title><link>https://rizwan-kh.github.io/tags/pipelines/</link><description>Recent content in pipelines on Rizwan Khanüë®üèª‚Äçüíª</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>&lt;a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">CC BY-NC 4.0&lt;/a></copyright><lastBuildDate>Tue, 06 Jun 2023 21:28:21 -0500</lastBuildDate><atom:link href="https://rizwan-kh.github.io/tags/pipelines/index.xml" rel="self" type="application/rss+xml"/><item><title>(Azure DevOps) ADF CI CD using Azure Pipeline</title><link>https://rizwan-kh.github.io/posts/2023/06/azure-devops-adf-ci-cd-using-azure-pipeline/</link><pubDate>Tue, 06 Jun 2023 21:28:21 -0500</pubDate><guid>https://rizwan-kh.github.io/posts/2023/06/azure-devops-adf-ci-cd-using-azure-pipeline/</guid><description>Automating Azure Data Factory deployments using Azure DevOps CI/CD Introduction In the ever-evolving landscape of data engineering, having a streamlined and automated process for deploying changes to Azure Data Factory (ADF) is crucial. Azure DevOps provides a robust platform for implementing Continuous Integration and Continuous Deployment (CI/CD) pipelines for ADF, allowing teams to deliver changes efficiently and maintain a reliable data processing workflow.
Why CI/CD for ADF? Azure Data Factory is a cloud-based data integration service that allows you to create, schedule, and manage data pipelines.</description></item><item><title>(Azure DevOps) Send Json Request(Parameters) to Azure Pipelines</title><link>https://rizwan-kh.github.io/posts/2021/06/azure-devops-send-json-requestparameters-to-azure-pipelines/</link><pubDate>Mon, 21 Jun 2021 11:16:23 +0400</pubDate><guid>https://rizwan-kh.github.io/posts/2021/06/azure-devops-send-json-requestparameters-to-azure-pipelines/</guid><description>Introduction If you&amp;rsquo;ve been using Azure DevOps, you would know that a pipeline can be triggered with runtime parameters in the format key: value pair and this is great for doing almost all of the tasks.
For our use case, we had been looking at an option to send a JSON-based parameter dictionary and I couldn&amp;rsquo;t find any way at the time of writing this article. We came up with a hack to achieve this and I would want to write it up in this blog post.</description></item><item><title>(Azure DevOps) Committing and Pushing to Azure Git Repository from Azure Pipeline</title><link>https://rizwan-kh.github.io/posts/2021/03/azure-devops-committing-and-pushing-to-azure-git-repository-from-azure-pipeline/</link><pubDate>Sun, 14 Mar 2021 00:28:21 +0400</pubDate><guid>https://rizwan-kh.github.io/posts/2021/03/azure-devops-committing-and-pushing-to-azure-git-repository-from-azure-pipeline/</guid><description>Azure Git Repository Workflow In a unique use-case scenario, we encountered the need to dynamically generate Terraform HCL files during Azure DevOps pipeline operations and subsequently commit and push these files back to Azure Git Repos. While this isn&amp;rsquo;t a conventional operation, we successfully achieved this using the pipeline configuration outlined below.
Assuming your pipeline has completed its tasks, including the generation or modification of files, the next step is to commit and push these changes to the Git repository.</description></item></channel></rss>